{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b13934-9209-4242-b816-dd0d136f83a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "#custom\n",
    "sys.path.append('./../../lib')\n",
    "import paths as paths\n",
    "import utils as utils\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12656005-0546-427d-88fc-910a52751141",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_base = Path(paths.dir_main)\n",
    "\n",
    "dir_out_figures = dir_base / \"outputs\"\n",
    "\n",
    "fn_avhrr = dir_base / \"avhrr_hotspots_masked.csv\"\n",
    "fn_modis_aqua_am = dir_base / \"aux_data/modis/MODIS_aqua_hotspots_masked_am.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a554ad6-a059-40b1-8fbc-b71f2c6dd1d9",
   "metadata": {},
   "source": [
    "load and unify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fd54f5a-ff9c-4dc1-a71e-c8aaba772879",
   "metadata": {},
   "outputs": [],
   "source": [
    "avhrr = pd.read_csv(str(fn_avhrr))\n",
    "avhrr = avhrr[['lat','lon180','lon360','dt_utc','dt_lst','month','year','doy','gfed','gfed_name']]\n",
    "avhrr['datetime'] = pd.to_datetime(avhrr['dt_lst'])\n",
    "avhrr['dt_utc'] = pd.to_datetime(avhrr['dt_utc'])\n",
    "avhrr = avhrr.rename(columns={'lat': 'latitude'})\n",
    "avhrr = avhrr.rename(columns={'lon180': 'longitude'})\n",
    "# remove years before 2003 (no good MODIS data)\n",
    "avhrr = avhrr.loc[avhrr.year > 2002,:]\n",
    "\n",
    "modis = pd.read_csv(str(fn_modis_aqua_am))\n",
    "modis['datetime'] = pd.to_datetime(modis['dt_lst'])\n",
    "modis['dt_utc'] = pd.to_datetime(modis['dt_utc'])\n",
    "modis = modis.rename(columns={'lat': 'latitude'})\n",
    "modis = modis.rename(columns={'lon180': 'longitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab928a6e-3bb3-4c6e-bfd4-11ca10614258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013,\n",
       "       2014, 2015, 2016], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(avhrr.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5b1cef6-2938-40a6-8182-debb34d96ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    latitude  longitude      lon360                        dt_utc                      dt_lst  month  year  doy  gfed gfed_name                   datetime\n",
      "0 -54.635223 -67.265503  292.734497 2001-12-23 05:04:06.155548096  2001-12-23 00:36:24.786590     12  2001  357     5      SHSA 2001-12-23 00:36:24.786590\n",
      "1 -54.620804 -67.312286  292.687714 2008-12-09 05:25:04.692649839  2008-12-09 01:03:28.218514     12  2008  344     5      SHSA 2008-12-09 01:03:28.218514\n",
      "2 -54.559692 -67.150970  292.849030 2011-10-24 05:30:17.506027220  2011-10-24 01:17:32.783680     10  2011  297     5      SHSA 2011-10-24 01:17:32.783680\n",
      "3 -54.115570 -70.304169  289.695831 1990-02-24 05:24:31.174049376  1990-02-24 00:29:37.475247      2  1990   55     5      SHSA 1990-02-24 00:29:37.475247\n",
      "4 -53.381866 -72.748322  287.251678 1996-01-22 06:00:23.641204834  1996-01-22 00:58:35.424258      1  1996   22     5      SHSA 1996-01-22 00:58:35.424258\n",
      "   latitude  longitude   lon360              dt_utc                      dt_lst  hours_lst    date_lst  month  year  doy  gfed gfed_name                   datetime\n",
      "0    8.1449    20.1377  20.1377 2003-01-01 00:26:00  2003-01-01 01:43:52.291951        1.0  2003-01-01      1  2003    1     8      NHAF 2003-01-01 01:43:52.291951\n",
      "1    8.1174    20.0504  20.0504 2003-01-19 00:14:00  2003-01-19 01:24:22.879528        1.0  2003-01-19      1  2003   19     8      NHAF 2003-01-19 01:24:22.879528\n",
      "2    8.1161    20.0594  20.0594 2003-01-19 00:14:00  2003-01-19 01:24:25.039528        1.0  2003-01-19      1  2003   19     8      NHAF 2003-01-19 01:24:25.039528\n",
      "3    7.3885    26.2658  26.2658 2003-01-01 00:26:00  2003-01-01 02:08:23.035951        2.0  2003-01-01      1  2003    1     8      NHAF 2003-01-01 02:08:23.035951\n",
      "4    7.3841    26.2686  26.2686 2003-01-01 00:26:00  2003-01-01 02:08:23.707951        2.0  2003-01-01      1  2003    1     8      NHAF 2003-01-01 02:08:23.707951\n"
     ]
    }
   ],
   "source": [
    "#print(avhrr.head())\n",
    "#print(modis.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832f71f-12ab-496f-8d81-382331e58aec",
   "metadata": {},
   "source": [
    "### process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb86b2-8e91-4699-a5aa-f98293d48146",
   "metadata": {},
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e83b649-5002-4c61-a21a-3ffd125293a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 1.0  # spatial grid size in degrees\n",
    "TEMPORAL_TOLERANCE = timedelta(hours=12)  # ±12h temporal window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2fd85-ca34-4bc4-bd06-d4b46ca20761",
   "metadata": {},
   "source": [
    "helper funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "022fadfd-3acd-48de-a322-d6482c2de0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_grid_cells(df, lat_col='latitude', lon_col='longitude'):\n",
    "    df = df.copy()\n",
    "    df['lat_bin'] = (np.floor(df[lat_col] / GRID_SIZE) * GRID_SIZE).astype(float)\n",
    "    df['lon_bin'] = (np.floor(df[lon_col] / GRID_SIZE) * GRID_SIZE).astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "def match_detections(modis_df, avhrr_df):\n",
    "    \"\"\"\n",
    "    Compare MODIS (truth) and AVHRR detections.\n",
    "    A true positive (TP) occurs when any AVHRR detection exists in the same grid cell\n",
    "    within the ±12 hour temporal tolerance of a MODIS detection.\n",
    "    \n",
    "    False negatives (FN) are MODIS detections with no AVHRR within tolerance.\n",
    "    False positives (FP) are AVHRR detections with no MODIS within tolerance.\n",
    "    \"\"\"\n",
    "    # Organize AVHRR detections by spatial grid cell\n",
    "    avhrr_lookup = defaultdict(list)\n",
    "    for idx, row in avhrr_df.iterrows():\n",
    "        key = (row['lat_bin'], row['lon_bin'])\n",
    "        avhrr_lookup[key].append((idx, row))\n",
    "\n",
    "    matched_avhrr_idx = set()\n",
    "    matched_modis = set()\n",
    "    fn_set = set()\n",
    "\n",
    "    for midx, modis_row in modis_df.iterrows():\n",
    "        key = (modis_row['lat_bin'], modis_row['lon_bin'])\n",
    "        candidates = avhrr_lookup.get(key, [])\n",
    "\n",
    "        matched = False\n",
    "        for cand_idx, cand in candidates:\n",
    "            if abs(modis_row['datetime'] - cand['datetime']) <= TEMPORAL_TOLERANCE:\n",
    "                matched = True\n",
    "                matched_modis.add(midx)\n",
    "                matched_avhrr_idx.add(cand_idx)\n",
    "        if not matched:\n",
    "            fn_set.add(midx)\n",
    "\n",
    "    # Check AVHRR for unmatched detections\n",
    "    fp_set = set()\n",
    "    for idx, row in avhrr_df.iterrows():\n",
    "        if idx not in matched_avhrr_idx:\n",
    "            key = (row['lat_bin'], row['lon_bin'])\n",
    "            # Only mark as FP if no MODIS is within tolerance\n",
    "            modis_candidates = modis_df[(modis_df['lat_bin'] == key[0]) &\n",
    "                                        (modis_df['lon_bin'] == key[1])]\n",
    "            if all(abs(row['datetime'] - m['datetime']) > TEMPORAL_TOLERANCE for _, m in modis_candidates.iterrows()):\n",
    "                fp_set.add(idx)\n",
    "\n",
    "    TP = len(matched_modis)\n",
    "    FN = len(fn_set)\n",
    "    FP = len(fp_set)\n",
    "\n",
    "    return TP, FN, FP\n",
    "\n",
    "def match_detections_vectorized(modis_df, avhrr_df):\n",
    "    \"\"\"\n",
    "    Vectorized comparison between MODIS (truth) and AVHRR detections.\n",
    "    A true positive (TP) occurs when any AVHRR detection exists in the same grid cell\n",
    "    within the ±12 hour temporal tolerance of a MODIS detection.\n",
    "    False negatives (FN) are MODIS detections with no AVHRR within tolerance.\n",
    "    False positives (FP) are AVHRR detections with no MODIS within tolerance.\n",
    "    \"\"\"\n",
    "    modis_df = modis_df.reset_index(drop=True).copy()\n",
    "    avhrr_df = avhrr_df.reset_index(drop=True).copy()\n",
    "    modis_df['index_modis'] = modis_df.index\n",
    "    avhrr_df['index_avhrr'] = avhrr_df.index\n",
    "    \n",
    "    \n",
    "    merged = pd.merge(modis_df, avhrr_df, on=['lat_bin', 'lon_bin'], suffixes=('_modis', '_avhrr'))\n",
    "    merged['time_diff'] = abs(merged['datetime_modis'] - merged['datetime_avhrr'])\n",
    "    \n",
    "    \n",
    "    matched = merged[merged['time_diff'] <= TEMPORAL_TOLERANCE]\n",
    "    \n",
    "    \n",
    "    matched_modis_idx = set(matched['index_modis'])\n",
    "    matched_avhrr_idx = set(matched['index_avhrr'])\n",
    "    \n",
    "    \n",
    "    TP = len(matched_modis_idx)\n",
    "    FN = len(modis_df) - TP\n",
    "    FP = len(avhrr_df) - len(matched_avhrr_idx)\n",
    "    \n",
    "    \n",
    "    return TP, FN, FP\n",
    "\n",
    "def compute_metrics(TP, FN, FP):\n",
    "    omission_rate = FN / (TP + FN) if (TP + FN) > 0 else np.nan\n",
    "    commission_rate = FP / (TP + FP) if (TP + FP) > 0 else np.nan\n",
    "    return omission_rate, commission_rate\n",
    "\n",
    "\n",
    "# def assign_region(df, region_mask, lat_bins, lon_bins):\n",
    "#     df = df.copy()\n",
    "#     region_ids = []\n",
    "#     for lat, lon in zip(df['latitude'], df['longitude']):\n",
    "#         lat_idx = np.digitize(lat, lat_bins) - 1\n",
    "#         lon_idx = np.digitize(lon, lon_bins) - 1\n",
    "#         if 0 <= lat_idx < region_mask.shape[0] and 0 <= lon_idx < region_mask.shape[1]:\n",
    "#             region_ids.append(region_mask[lat_idx, lon_idx])\n",
    "#         else:\n",
    "#             region_ids.append(-1)\n",
    "#     df['region_id'] = region_ids\n",
    "#     return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8baa3-5e98-44b5-a1cf-8d1b0805eac3",
   "metadata": {},
   "source": [
    "main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc72629-3065-48ca-996e-1a86db2caf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(modis_df, avhrr_df, region_mask=None):\n",
    "    # Ensure datetime\n",
    "    modis_df['datetime'] = pd.to_datetime(modis_df['datetime'])\n",
    "    avhrr_df['datetime'] = pd.to_datetime(avhrr_df['datetime'])\n",
    "\n",
    "    # Assign grid cells\n",
    "    modis_df = assign_grid_cells(modis_df)\n",
    "    avhrr_df = assign_grid_cells(avhrr_df)\n",
    "\n",
    "    # Add year for grouping\n",
    "    modis_df['year'] = modis_df['datetime'].dt.year\n",
    "    avhrr_df['year'] = avhrr_df['datetime'].dt.year\n",
    "\n",
    "    results = []\n",
    "\n",
    "    if region_mask is not None:\n",
    "        # Define grid for region assignment\n",
    "        lat_bins = np.arange(-90, 90 + GRID_SIZE, GRID_SIZE)\n",
    "        lon_bins = np.arange(-180, 180 + GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "        modis_df = assign_region(modis_df, region_mask, lat_bins, lon_bins)\n",
    "        avhrr_df = assign_region(avhrr_df, region_mask, lat_bins, lon_bins)\n",
    "\n",
    "        region_ids = sorted(set(modis_df['region_id']) & set(avhrr_df['region_id']))\n",
    "\n",
    "        for region in region_ids:\n",
    "            modis_r = modis_df[modis_df['region_id'] == region]\n",
    "            avhrr_r = avhrr_df[avhrr_df['region_id'] == region]\n",
    "\n",
    "            # All years\n",
    "            TP, FN, FP = match_detections(modis_r, avhrr_r)\n",
    "            omission, commission = compute_metrics(TP, FN, FP)\n",
    "            results.append({'region': region, 'year': 'All', 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                            'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "            # Per year\n",
    "            years = sorted(set(modis_r['year']) | set(avhrr_r['year']))\n",
    "            for year in years:\n",
    "                modis_y = modis_r[modis_r['year'] == year]\n",
    "                avhrr_y = avhrr_r[avhrr_r['year'] == year]\n",
    "                TP, FN, FP = match_detections(modis_y, avhrr_y)\n",
    "                omission, commission = compute_metrics(TP, FN, FP)\n",
    "                results.append({'region': region, 'year': year, 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                                'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "    else:\n",
    "        # ---- Overall (multi-year) analysis ----\n",
    "        print(f'doing multi-year analysis')\n",
    "        TP, FN, FP = match_detections(modis_df, avhrr_df)\n",
    "        omission, commission = compute_metrics(TP, FN, FP)\n",
    "        results.append({'region': 'Global', 'year': 'All', 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                        'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "        # ---- Per-year analysis ----\n",
    "        years = sorted(set(modis_df['year']) | set(avhrr_df['year']))\n",
    "        if len(years) > 1:\n",
    "            for year in years:\n",
    "                print(f'doing year {year}')\n",
    "                modis_y = modis_df[modis_df['year'] == year]\n",
    "                avhrr_y = avhrr_df[avhrr_df['year'] == year]\n",
    "    \n",
    "                TP, FN, FP = match_detections(modis_y, avhrr_y)\n",
    "                omission, commission = compute_metrics(TP, FN, FP)\n",
    "                results.append({'region': 'Global', 'year': year, 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                                'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34e87519-cbb5-4bc7-b57e-386d06172bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing multi-year analysis\n",
      "   region year     TP     FN    FP  omission_rate  commission_rate\n",
      "0  Global  All  24444  81482  9676       0.769235         0.283587\n"
     ]
    }
   ],
   "source": [
    "# result_df = run_analysis(modis_df=modis.loc[modis.year == 2016,:].copy(), \n",
    "#                          avhrr_df=avhrr.loc[avhrr.year == 2016,:].copy(), \n",
    "#                          region_mask=None)\n",
    "# print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd617ab-e1e2-43a6-8db4-ccd7e2ea64a5",
   "metadata": {},
   "source": [
    "a ~0.77 omission rate is actually in line with expectations; due to the GAC resampling scheme, you only end up with information from 4 of every 15 LAC pixels (which are 1km, comparable to MODIS). so all else being equal, AVHRR should at best detect 4/15ths as much fire as modis (4/15 = 0.27, 1-0.27 = 0.73)\n",
    "\n",
    "The detection rate should in fact be even lower, because the 4 LAC pixels are averaged to get 1 GAC pixel, which will further supress detection - easily explaining omission rate of 0.77.\n",
    "\n",
    "More problematic is a comission rate of 0.28.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f3d140e-7c11-4c05-82ba-b4951d5fce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666666666666"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d76f062-cd62-4d4d-ba66-1c67343ff9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(modis_df, avhrr_df, calc_overall_error=False, regional=False):\n",
    "    \"\"\"\n",
    "    Run omission/commission analysis.\n",
    "    If regional=True, break down results by 'gfed' regions.\n",
    "    Always outputs global results overall and by year.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Ensure datetime format\n",
    "    modis_df['datetime'] = pd.to_datetime(modis_df['datetime'])\n",
    "    avhrr_df['datetime'] = pd.to_datetime(avhrr_df['datetime'])\n",
    "\n",
    "    # Assign grid cells\n",
    "    modis_df = assign_grid_cells(modis_df)\n",
    "    avhrr_df = assign_grid_cells(avhrr_df)\n",
    "\n",
    "    # Add year\n",
    "    modis_df['year'] = modis_df['datetime'].dt.year\n",
    "    avhrr_df['year'] = avhrr_df['datetime'].dt.year\n",
    "\n",
    "    # ---- Global analysis ----\n",
    "    if calc_overall_error:\n",
    "        print(f'doing global - all years. Note: This will be slow; the vectorized solution causes out of memory errors so this is run iteratively.')\n",
    "        TP, FN, FP = match_detections(modis_df, avhrr_df)\n",
    "        #TP, FN, FP = match_detections_vectorized(modis_df, avhrr_df) <-- causes memory errors!\n",
    "        omission, commission = compute_metrics(TP, FN, FP)\n",
    "        results.append({'region': 'Global', 'year': 'All', 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                        'omission_rate': omission, 'commission_rate': commission})\n",
    "    else:\n",
    "        print(f'skipping global - all years.')\n",
    "    \n",
    "    years = sorted(set(modis_df['year']).intersection(set(avhrr_df['year'])))\n",
    "    print(f'\\nIndividual years to run: {years}\\n')\n",
    "    \n",
    "    for year in years:\n",
    "        print(f'doing global - year {year}')\n",
    "        modis_y = modis_df[modis_df['year'] == year]\n",
    "        avhrr_y = avhrr_df[avhrr_df['year'] == year]\n",
    "        #TP, FN, FP = match_detections(modis_y, avhrr_y)\n",
    "        TP, FN, FP = match_detections_vectorized(modis_y, avhrr_y)\n",
    "        omission, commission = compute_metrics(TP, FN, FP)\n",
    "        results.append({'region': 'Global', 'year': year, 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                        'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "    # ---- Regional analysis ----\n",
    "    if regional:\n",
    "        regions = sorted(set(modis_df['gfed']).intersection(set(avhrr_df['gfed'])))\n",
    "        print(f'\\nRunning regional. \\nIndividual regions to run: {regions}\\n')\n",
    "        for region in regions:\n",
    "            print(f'doing regional - all years. Region: {region}')\n",
    "            modis_r = modis_df[modis_df['gfed'] == region]\n",
    "            avhrr_r = avhrr_df[avhrr_df['gfed'] == region]\n",
    "            #TP, FN, FP = match_detections(modis_r, avhrr_r)\n",
    "            TP, FN, FP = match_detections_vectorized(modis_r, avhrr_r)\n",
    "            omission, commission = compute_metrics(TP, FN, FP)\n",
    "            gfed_name = modis_r['gfed_name'].iloc[0] if not modis_r.empty else avhrr_r['gfed_name'].iloc[0]\n",
    "            results.append({'region': gfed_name, 'year': 'All', 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                            'omission_rate': omission, 'commission_rate': commission})\n",
    "            \n",
    "            for year in sorted(set(modis_r['year']).intersection(set(avhrr_r['year']))):\n",
    "                print(f'doing region {region} - year {year}')\n",
    "                modis_y = modis_r[modis_r['year'] == year]\n",
    "                avhrr_y = avhrr_r[avhrr_r['year'] == year]\n",
    "                #TP, FN, FP = match_detections(modis_y, avhrr_y)\n",
    "                TP, FN, FP = match_detections_vectorized(modis_y, avhrr_y)\n",
    "                omission, commission = compute_metrics(TP, FN, FP)\n",
    "                results.append({'region': gfed_name, 'year': year, 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                                'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca17468f-5b1e-48dc-ba2e-a2ff0f5fbce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing global - all years\n",
      "Individual years to run: [2003]\n",
      "doing global - year 2003\n",
      "   region  year     TP     FN      FP  omission_rate  commission_rate\n",
      "0  Global   All  36391  99845  275560       0.732883         0.883344\n",
      "1  Global  2003  36391  99845   14161       0.732883         0.280127\n"
     ]
    }
   ],
   "source": [
    "result_df = run_analysis(modis_df=modis.loc[modis.year < 2004,:].copy(), \n",
    "                         avhrr_df=avhrr.loc[avhrr.year < 2004,:].copy(), \n",
    "                         regional=False)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cd82894-323a-42bd-9b33-89e3ac5b10c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping global - all years.\n",
      "\n",
      "Individual years to run: [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n",
      "\n",
      "doing global - year 2003\n",
      "doing global - year 2004\n",
      "doing global - year 2005\n",
      "doing global - year 2006\n",
      "doing global - year 2007\n",
      "doing global - year 2008\n",
      "doing global - year 2009\n",
      "doing global - year 2010\n",
      "doing global - year 2011\n",
      "doing global - year 2012\n",
      "doing global - year 2013\n",
      "doing global - year 2014\n",
      "doing global - year 2015\n",
      "doing global - year 2016\n",
      "    region  year     TP      FN     FP  omission_rate  commission_rate\n",
      "0   Global  2003  36391   99845  14161       0.732883         0.280127\n",
      "1   Global  2004  33795  104563  13490       0.755742         0.285291\n",
      "2   Global  2005  29628  109573  12398       0.787157         0.295008\n",
      "3   Global  2006  35783   91672  11906       0.719250         0.249659\n",
      "4   Global  2007  42498  113358  13892       0.727325         0.246356\n",
      "5   Global  2008  31848   79161  12722       0.713104         0.285439\n",
      "6   Global  2009  26154   75738  11230       0.743316         0.300396\n",
      "7   Global  2010  35568  101084  12211       0.739718         0.255573\n",
      "8   Global  2011  32566   93611  10876       0.741902         0.250357\n",
      "9   Global  2012  36430  118102  10451       0.764256         0.222926\n",
      "10  Global  2013  22604   65076   9984       0.742199         0.306370\n",
      "11  Global  2014  27477   76834  10667       0.736586         0.279651\n",
      "12  Global  2015  39945  102223  11802       0.719030         0.228071\n",
      "13  Global  2016  24444   81482   9676       0.769235         0.283587\n"
     ]
    }
   ],
   "source": [
    "result_df = run_analysis(modis_df=modis.loc[:].copy(), \n",
    "                         avhrr_df=avhrr.loc[:].copy(), \n",
    "                         calc_overall_error=False,\n",
    "                         regional=False)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7a50a90-0a1d-45aa-a6f7-dc0be5eba903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region  year     TP     FN    FP  omission_rate  commission_rate\n",
      "0  Global   All  24444  81482  9676       0.769235         0.283587\n",
      "1  Global  2016  24444  81482  9676       0.769235         0.283587\n"
     ]
    }
   ],
   "source": [
    "#print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76823487-785f-4bed-9d8b-a7f03224dfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     region  year     TP      FN     FP  omission_rate  commission_rate\n",
      "0    Global   All  80027  176930  69776       0.688559         0.465785\n",
      "1    Global  1986      0       0   2619            NaN         1.000000\n",
      "2    Global  1989      0       0   3390            NaN         1.000000\n",
      "3    Global  1990      0       0   4026            NaN         1.000000\n",
      "4    Global  1991      0       0   4804            NaN         1.000000\n",
      "..      ...   ...    ...     ...    ...            ...              ...\n",
      "374    AUST  2012    860    1496    286       0.634975         0.249564\n",
      "375    AUST  2013    243     460    134       0.654339         0.355438\n",
      "376    AUST  2014    329     701    237       0.680583         0.418728\n",
      "377    AUST  2015    182     640    123       0.778589         0.403279\n",
      "378    AUST  2016    168     512     94       0.752941         0.358779\n",
      "\n",
      "[379 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# result_df = run_analysis(modis_df=modis.loc[modis.month == 8,:].copy(), \n",
    "#                          avhrr_df=avhrr.loc[avhrr.month == 8,:].copy(), \n",
    "#                          regional=True)\n",
    "# print(result_df)\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578e328-8bb7-4a70-8136-ebba9f4fed48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
