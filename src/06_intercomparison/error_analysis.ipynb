{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0b13934-9209-4242-b816-dd0d136f83a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "import datetime as dt\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "#custom\n",
    "sys.path.append('./../../lib')\n",
    "import paths as paths\n",
    "import utils as utils\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08fdccd-7ae8-4542-8684-2af34f187575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12656005-0546-427d-88fc-910a52751141",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_base = Path(paths.dir_main)\n",
    "\n",
    "dir_out_figures = dir_base / \"outputs\"\n",
    "\n",
    "fn_avhrr = dir_base / \"avhrr_hotspots_masked.csv\"\n",
    "fn_modis_aqua_am = dir_base / \"aux_data/modis/MODIS_aqua_hotspots_masked_am.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a554ad6-a059-40b1-8fbc-b71f2c6dd1d9",
   "metadata": {},
   "source": [
    "load and unify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fd54f5a-ff9c-4dc1-a71e-c8aaba772879",
   "metadata": {},
   "outputs": [],
   "source": [
    "avhrr = pd.read_csv(str(fn_avhrr))\n",
    "avhrr = avhrr[['lat','lon180','lon360','dt_utc','dt_lst','month','year','doy','gfed','gfed_name']]\n",
    "avhrr['datetime'] = pd.to_datetime(avhrr['dt_lst'])\n",
    "avhrr['dt_utc'] = pd.to_datetime(avhrr['dt_utc'])\n",
    "avhrr = avhrr.rename(columns={'lat': 'latitude'})\n",
    "avhrr = avhrr.rename(columns={'lon180': 'longitude'})\n",
    "\n",
    "modis = pd.read_csv(str(fn_modis_aqua_am))\n",
    "modis['datetime'] = pd.to_datetime(modis['dt_lst'])\n",
    "modis['dt_utc'] = pd.to_datetime(modis['dt_utc'])\n",
    "modis = modis.rename(columns={'lat': 'latitude'})\n",
    "modis = modis.rename(columns={'lon180': 'longitude'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab928a6e-3bb3-4c6e-bfd4-11ca10614258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(avhrr.gfed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5b1cef6-2938-40a6-8182-debb34d96ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    latitude  longitude      lon360                        dt_utc                      dt_lst  month  year  doy  gfed gfed_name                   datetime\n",
      "0 -54.635223 -67.265503  292.734497 2001-12-23 05:04:06.155548096  2001-12-23 00:36:24.786590     12  2001  357     5      SHSA 2001-12-23 00:36:24.786590\n",
      "1 -54.620804 -67.312286  292.687714 2008-12-09 05:25:04.692649839  2008-12-09 01:03:28.218514     12  2008  344     5      SHSA 2008-12-09 01:03:28.218514\n",
      "2 -54.559692 -67.150970  292.849030 2011-10-24 05:30:17.506027220  2011-10-24 01:17:32.783680     10  2011  297     5      SHSA 2011-10-24 01:17:32.783680\n",
      "3 -54.115570 -70.304169  289.695831 1990-02-24 05:24:31.174049376  1990-02-24 00:29:37.475247      2  1990   55     5      SHSA 1990-02-24 00:29:37.475247\n",
      "4 -53.381866 -72.748322  287.251678 1996-01-22 06:00:23.641204834  1996-01-22 00:58:35.424258      1  1996   22     5      SHSA 1996-01-22 00:58:35.424258\n",
      "   latitude  longitude   lon360              dt_utc                      dt_lst  hours_lst    date_lst  month  year  doy  gfed gfed_name                   datetime\n",
      "0    8.1449    20.1377  20.1377 2003-01-01 00:26:00  2003-01-01 01:43:52.291951        1.0  2003-01-01      1  2003    1     8      NHAF 2003-01-01 01:43:52.291951\n",
      "1    8.1174    20.0504  20.0504 2003-01-19 00:14:00  2003-01-19 01:24:22.879528        1.0  2003-01-19      1  2003   19     8      NHAF 2003-01-19 01:24:22.879528\n",
      "2    8.1161    20.0594  20.0594 2003-01-19 00:14:00  2003-01-19 01:24:25.039528        1.0  2003-01-19      1  2003   19     8      NHAF 2003-01-19 01:24:25.039528\n",
      "3    7.3885    26.2658  26.2658 2003-01-01 00:26:00  2003-01-01 02:08:23.035951        2.0  2003-01-01      1  2003    1     8      NHAF 2003-01-01 02:08:23.035951\n",
      "4    7.3841    26.2686  26.2686 2003-01-01 00:26:00  2003-01-01 02:08:23.707951        2.0  2003-01-01      1  2003    1     8      NHAF 2003-01-01 02:08:23.707951\n"
     ]
    }
   ],
   "source": [
    "print(avhrr.head())\n",
    "print(modis.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832f71f-12ab-496f-8d81-382331e58aec",
   "metadata": {},
   "source": [
    "### process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bb86b2-8e91-4699-a5aa-f98293d48146",
   "metadata": {},
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e83b649-5002-4c61-a21a-3ffd125293a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_SIZE = 1.0  # spatial grid size in degrees\n",
    "TEMPORAL_TOLERANCE = timedelta(hours=12)  # ±12h temporal window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2fd85-ca34-4bc4-bd06-d4b46ca20761",
   "metadata": {},
   "source": [
    "helper funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "022fadfd-3acd-48de-a322-d6482c2de0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_grid_cells(df, lat_col='latitude', lon_col='longitude'):\n",
    "    df = df.copy()\n",
    "    df['lat_bin'] = (np.floor(df[lat_col] / GRID_SIZE) * GRID_SIZE).astype(float)\n",
    "    df['lon_bin'] = (np.floor(df[lon_col] / GRID_SIZE) * GRID_SIZE).astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "def match_detections(modis_df, avhrr_df):\n",
    "    \"\"\"\n",
    "    Compare MODIS (truth) and AVHRR detections.\n",
    "    A true positive (TP) occurs when any AVHRR detection exists in the same grid cell\n",
    "    within the ±12 hour temporal tolerance of a MODIS detection.\n",
    "    \n",
    "    False negatives (FN) are MODIS detections with no AVHRR within tolerance.\n",
    "    False positives (FP) are AVHRR detections with no MODIS within tolerance.\n",
    "    \"\"\"\n",
    "    # Organize AVHRR detections by spatial grid cell\n",
    "    avhrr_lookup = defaultdict(list)\n",
    "    for idx, row in avhrr_df.iterrows():\n",
    "        key = (row['lat_bin'], row['lon_bin'])\n",
    "        avhrr_lookup[key].append((idx, row))\n",
    "\n",
    "    matched_avhrr_idx = set()\n",
    "    matched_modis = set()\n",
    "    fn_set = set()\n",
    "\n",
    "    for midx, modis_row in modis_df.iterrows():\n",
    "        key = (modis_row['lat_bin'], modis_row['lon_bin'])\n",
    "        candidates = avhrr_lookup.get(key, [])\n",
    "\n",
    "        matched = False\n",
    "        for cand_idx, cand in candidates:\n",
    "            if abs(modis_row['datetime'] - cand['datetime']) <= TEMPORAL_TOLERANCE:\n",
    "                matched = True\n",
    "                matched_modis.add(midx)\n",
    "                matched_avhrr_idx.add(cand_idx)\n",
    "        if not matched:\n",
    "            fn_set.add(midx)\n",
    "\n",
    "    # Check AVHRR for unmatched detections\n",
    "    fp_set = set()\n",
    "    for idx, row in avhrr_df.iterrows():\n",
    "        if idx not in matched_avhrr_idx:\n",
    "            key = (row['lat_bin'], row['lon_bin'])\n",
    "            # Only mark as FP if no MODIS is within tolerance\n",
    "            modis_candidates = modis_df[(modis_df['lat_bin'] == key[0]) &\n",
    "                                        (modis_df['lon_bin'] == key[1])]\n",
    "            if all(abs(row['datetime'] - m['datetime']) > TEMPORAL_TOLERANCE for _, m in modis_candidates.iterrows()):\n",
    "                fp_set.add(idx)\n",
    "\n",
    "    TP = len(matched_modis)\n",
    "    FN = len(fn_set)\n",
    "    FP = len(fp_set)\n",
    "\n",
    "    return TP, FN, FP\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(TP, FN, FP):\n",
    "    omission_rate = FN / (TP + FN) if (TP + FN) > 0 else np.nan\n",
    "    commission_rate = FP / (TP + FP) if (TP + FP) > 0 else np.nan\n",
    "    return omission_rate, commission_rate\n",
    "\n",
    "\n",
    "def assign_region(df, region_mask, lat_bins, lon_bins):\n",
    "    df = df.copy()\n",
    "    region_ids = []\n",
    "    for lat, lon in zip(df['latitude'], df['longitude']):\n",
    "        lat_idx = np.digitize(lat, lat_bins) - 1\n",
    "        lon_idx = np.digitize(lon, lon_bins) - 1\n",
    "        if 0 <= lat_idx < region_mask.shape[0] and 0 <= lon_idx < region_mask.shape[1]:\n",
    "            region_ids.append(region_mask[lat_idx, lon_idx])\n",
    "        else:\n",
    "            region_ids.append(-1)\n",
    "    df['region_id'] = region_ids\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8baa3-5e98-44b5-a1cf-8d1b0805eac3",
   "metadata": {},
   "source": [
    "main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fc72629-3065-48ca-996e-1a86db2caf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(modis_df, avhrr_df, region_mask=None):\n",
    "    # Ensure datetime\n",
    "    modis_df['datetime'] = pd.to_datetime(modis_df['datetime'])\n",
    "    avhrr_df['datetime'] = pd.to_datetime(avhrr_df['datetime'])\n",
    "\n",
    "    # Assign grid cells\n",
    "    modis_df = assign_grid_cells(modis_df)\n",
    "    avhrr_df = assign_grid_cells(avhrr_df)\n",
    "\n",
    "    # Add year for grouping\n",
    "    #modis_df['year'] = modis_df['datetime'].dt.year\n",
    "    #avhrr_df['year'] = avhrr_df['datetime'].dt.year\n",
    "\n",
    "    results = []\n",
    "\n",
    "    if region_mask is not None:\n",
    "        # Define grid for region assignment\n",
    "        lat_bins = np.arange(-90, 90 + GRID_SIZE, GRID_SIZE)\n",
    "        lon_bins = np.arange(-180, 180 + GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "        modis_df = assign_region(modis_df, region_mask, lat_bins, lon_bins)\n",
    "        avhrr_df = assign_region(avhrr_df, region_mask, lat_bins, lon_bins)\n",
    "\n",
    "        region_ids = sorted(set(modis_df['region_id']) & set(avhrr_df['region_id']))\n",
    "\n",
    "        for region in region_ids:\n",
    "            modis_r = modis_df[modis_df['region_id'] == region]\n",
    "            avhrr_r = avhrr_df[avhrr_df['region_id'] == region]\n",
    "\n",
    "            # All years\n",
    "            TP, FN, FP = match_detections(modis_r, avhrr_r)\n",
    "            omission, commission = compute_metrics(TP, FN, FP)\n",
    "            results.append({'region': region, 'year': 'All', 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                            'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "            # Per year\n",
    "            years = sorted(set(modis_r['year']) | set(avhrr_r['year']))\n",
    "            for year in years:\n",
    "                modis_y = modis_r[modis_r['year'] == year]\n",
    "                avhrr_y = avhrr_r[avhrr_r['year'] == year]\n",
    "                TP, FN, FP = match_detections(modis_y, avhrr_y)\n",
    "                omission, commission = compute_metrics(TP, FN, FP)\n",
    "                results.append({'region': region, 'year': year, 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                                'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "    else:\n",
    "        # ---- Overall (multi-year) analysis ----\n",
    "        print(f'doing multi-year analysis')\n",
    "        TP, FN, FP = match_detections(modis_df, avhrr_df)\n",
    "        omission, commission = compute_metrics(TP, FN, FP)\n",
    "        results.append({'region': 'Global', 'year': 'All', 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                        'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "        # ---- Per-year analysis ----\n",
    "        years = sorted(set(modis_df['year']) | set(avhrr_df['year']))\n",
    "        if len(years) > 1:\n",
    "            for year in years:\n",
    "                print(f'doing year {year}')\n",
    "                modis_y = modis_df[modis_df['year'] == year]\n",
    "                avhrr_y = avhrr_df[avhrr_df['year'] == year]\n",
    "    \n",
    "                TP, FN, FP = match_detections(modis_y, avhrr_y)\n",
    "                omission, commission = compute_metrics(TP, FN, FP)\n",
    "                results.append({'region': 'Global', 'year': year, 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                                'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34e87519-cbb5-4bc7-b57e-386d06172bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing multi-year analysis\n",
      "   region year     TP     FN    FP  omission_rate  commission_rate\n",
      "0  Global  All  24444  81482  9676       0.769235         0.283587\n"
     ]
    }
   ],
   "source": [
    "result_df = run_analysis(modis_df=modis.loc[modis.year == 2016,:].copy(), \n",
    "                         avhrr_df=avhrr.loc[avhrr.year == 2016,:].copy(), \n",
    "                         region_mask=None)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd617ab-e1e2-43a6-8db4-ccd7e2ea64a5",
   "metadata": {},
   "source": [
    "a ~0.77 omission rate is actually in line with expectations; due to the GAC resampling scheme, you only end up with information from 4 of every 15 LAC pixels (which are 1km, comparable to MODIS). so all else being equal, AVHRR should at best detect 4/15ths as much fire as modis (4/15 = 0.27, 1-0.27 = 0.73)\n",
    "\n",
    "The detection rate should in fact be even lower, because the 4 LAC pixels are averaged to get 1 GAC pixel, which will further supress detection - easily explaining omission rate of 0.77.\n",
    "\n",
    "More problematic is a comission rate of 0.28.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f3d140e-7c11-4c05-82ba-b4951d5fce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666666666666"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d76f062-cd62-4d4d-ba66-1c67343ff9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(modis_df, avhrr_df, regional=False):\n",
    "    \"\"\"\n",
    "    Run omission/commission analysis.\n",
    "    If regional=True, break down results by 'gfed' regions.\n",
    "    Always outputs global results overall and by year.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Ensure datetime format\n",
    "    modis_df['datetime'] = pd.to_datetime(modis_df['datetime'])\n",
    "    avhrr_df['datetime'] = pd.to_datetime(avhrr_df['datetime'])\n",
    "\n",
    "    # Assign grid cells\n",
    "    modis_df = assign_grid_cells(modis_df)\n",
    "    avhrr_df = assign_grid_cells(avhrr_df)\n",
    "\n",
    "    # Add year\n",
    "    modis_df['year'] = modis_df['datetime'].dt.year\n",
    "    avhrr_df['year'] = avhrr_df['datetime'].dt.year\n",
    "\n",
    "    # ---- Global analysis ----\n",
    "    TP, FN, FP = match_detections(modis_df, avhrr_df)\n",
    "    omission, commission = compute_metrics(TP, FN, FP)\n",
    "    results.append({'region': 'Global', 'year': 'All', 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                    'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "    for year in sorted(set(modis_df['year']).union(set(avhrr_df['year']))):\n",
    "        modis_y = modis_df[modis_df['year'] == year]\n",
    "        avhrr_y = avhrr_df[avhrr_df['year'] == year]\n",
    "        TP, FN, FP = match_detections(modis_y, avhrr_y)\n",
    "        omission, commission = compute_metrics(TP, FN, FP)\n",
    "        results.append({'region': 'Global', 'year': year, 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                        'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "    # ---- Regional analysis ----\n",
    "    if regional:\n",
    "        regions = sorted(set(modis_df['gfed']).union(set(avhrr_df['gfed'])))\n",
    "        for region in regions:\n",
    "            print(region)\n",
    "            modis_r = modis_df[modis_df['gfed'] == region]\n",
    "            avhrr_r = avhrr_df[avhrr_df['gfed'] == region]\n",
    "            TP, FN, FP = match_detections(modis_r, avhrr_r)\n",
    "            omission, commission = compute_metrics(TP, FN, FP)\n",
    "            gfed_name = modis_r['gfed_name'].iloc[0] if not modis_r.empty else avhrr_r['gfed_name'].iloc[0]\n",
    "            results.append({'region': gfed_name, 'year': 'All', 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                            'omission_rate': omission, 'commission_rate': commission})\n",
    "            for year in sorted(set(modis_r['year']).union(set(avhrr_r['year']))):\n",
    "                modis_y = modis_r[modis_r['year'] == year]\n",
    "                avhrr_y = avhrr_r[avhrr_r['year'] == year]\n",
    "                TP, FN, FP = match_detections(modis_y, avhrr_y)\n",
    "                omission, commission = compute_metrics(TP, FN, FP)\n",
    "                results.append({'region': gfed_name, 'year': year, 'TP': TP, 'FN': FN, 'FP': FP,\n",
    "                                'omission_rate': omission, 'commission_rate': commission})\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca17468f-5b1e-48dc-ba2e-a2ff0f5fbce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = run_analysis(modis_df=modis.loc[modis.year == 2016,:].copy(), \n",
    "                         avhrr_df=avhrr.loc[avhrr.year == 2016,:].copy(), \n",
    "                         regional=False)\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7a50a90-0a1d-45aa-a6f7-dc0be5eba903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region  year     TP     FN    FP  omission_rate  commission_rate\n",
      "0  Global   All  24444  81482  9676       0.769235         0.283587\n",
      "1  Global  2016  24444  81482  9676       0.769235         0.283587\n"
     ]
    }
   ],
   "source": [
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76823487-785f-4bed-9d8b-a7f03224dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = run_analysis(modis_df=modis.loc[modis.month == 8,:].copy(), \n",
    "                         avhrr_df=avhrr.loc[avhrr.month == 8,:].copy(), \n",
    "                         regional=True)\n",
    "print(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
